{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tutorial: Generative Adversarial Networks - Advanced Techniques\n",
    "### - *Jonas Glombitza, RWTH Aachen University, IML 2019, CERN*\n",
    "This tutorial is about _generative models_ and especially **Generative Adversarial Networks** (**GANs**).\n",
    "In this tutorial we will implement different types of GANs, which were proposed recently:\n",
    "- Vanilla GAN - https://arxiv.org/abs/1406.2661\n",
    "- Conditional GAN - https://arxiv.org/abs/1610.09585\n",
    "- Wasserstein GAN (WGAN-GP) - https://arxiv.org/abs/1704.00028\n",
    "- Spectral Normalization SN-GAN - https://arxiv.org/abs/1802.05957\n",
    "\n",
    "and learn about further techniques to stabilize the training of GANs. (DCGANs, conditioning of the generator ...).\n",
    "To train our generative models, we will have a look on three different data sets (1 from computer vision, 2 physics data sets):\n",
    "1. [ CIFAR10 ](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "2. [ Footprints of Cosmic Ray induced Air Showers ](https://link.springer.com/article/10.1007/s41781-018-0008-x)\n",
    "3. [ Electromagnetic Calorimeter Images (multi-layer) ](https://doi.org/10.1007/s41781-018-0019-7)\n",
    "\n",
    "As framework, we make use of [TensorFlow](https://www.tensorflow.org/) and especially:\n",
    "- [Keras](https://keras.io/): Keras API shipped with TensorFlow\n",
    "- [TensorFlow-GAN](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/gan): lightweight library for training GANs\n",
    "\n",
    "#### Table of contents\n",
    "1. [ Basics ](#basics)\n",
    "\n",
    "2. [ Generative Adversarial Networks ](#gan)\n",
    " 1. [ Theory ](#gan_theory)\n",
    " 2. [ CIFAR10: Example](#gan_code)\n",
    " 3. [Implementation](#gan_code)\n",
    " \n",
    "3. [ Wasserstein GANs ](#wgan)\n",
    " 1. [ Theory ](#wgan_theory)\n",
    " 2. [ CIFAR10: Example](#wgan_code)\n",
    " 3. [ Results](#wgan_result)\n",
    " \n",
    "4. [ Spectral Normalization for GANs ](#sngan)\n",
    " 1. [ Theory ](#sngan_theory)\n",
    " 2. [ Physics Example: Cosmic Ray induces Air Showers](#sngan_code)\n",
    " 3. [ Results](#sngan_result)\n",
    " \n",
    "5. [ Calorimeter Images](#calgan)\n",
    " 1. [ Generator conditioning ](#calgan_theory)\n",
    " 2. [ Physics Example: Calorimeter images](#calgan_code)\n",
    " 3. [ Results](#calgan_result)\n",
    "   \n",
    "   \n",
    "<a name=\"basics\"></a>\n",
    "## Basics\n",
    "\n",
    "\n",
    "<details><summary> <button type=\"button\">Display detailed text</button> </summary>\n",
    "<p>\n",
    "\n",
    "### Generative models\n",
    "Before we jump in to the implementation of several GANs, we need to introduce _Generative Models_.\n",
    "\n",
    "Let us assume we have a bunch of images which forms the distribution of real images $P_{r}$.\n",
    "In our case (CIFAR10 dataset) the distribution consists of several classes: `horse, airplane, bird, frog, truck, deer, cat, dog, car, ship`.\n",
    "Instead of training a classifier to be able to label our data we now would like to generate samples which are \n",
    "similar to samples in the distributio $P_{r}$ formed by the bunch of images.\n",
    "The clue is, that we would like t generate **new samples** which were **not part** of the dataset, but look really similar.\n",
    " \n",
    "![CIFAR 10 Image](images/CIFAR10_collection.png)\n",
    "\n",
    "So in a mathematical way, we would like to approximate the real distribution $P_{r}$ with a model $P_{\\theta}$.\n",
    "With this *generative* model, we then would like to generate new samples out of our approximation $x \\sim P_{\\theta}$.\n",
    "\n",
    "<a name=\"gan\"></a>\n",
    "### Generative Adversarial Networks\n",
    "The basic idea of Generative Adversarial Networks (GANs) is to train a **generator network** to learn the underlying distribution.<sup>[1](#myfootnote1)</sup>\n",
    "In other words, we would like to design a generator machine, we can feed with noise and which outputs us nice samples following\n",
    "the distribution of real images $P_{r}$, but which were not part of the training dataset.\n",
    "So in our case, we would like to generate new samples of airplanes, cars, dogs etc..\n",
    " \n",
    " <img src=\"images/generator_machine.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "In our setup we use a neural network $G(z)$ as generator machine. \n",
    "The generator network $G(z)$ gets as input a noise vector $z$ sampled from a muldimensional noise distribution $z \\sim p(z)$.\n",
    "This space of $z$ is often called the latent space. The generator should then map the noise vector $z$ into the data space (the space where our\n",
    "real data samples lie) and output new samples/images $\\tilde{x} \\sim G(z)$. We would like to have these $\\tilde{x}$ very similar to the real samples $x \\sim P_{r}$.\n",
    "\n",
    "For the training of our generator network we need feedback, if the generated samples are of good or bad quality.\n",
    "Because a classical supervised loss is incapable for giving a good feedback to the generator network, it is trained in an unsupervised manner.\n",
    "So instead of using \"mean squared error\" or similar metrics, the performance measure is given by a **second** _adversarial_ neural network, which is called _discriminator_.\n",
    "In the vanilla GAN setup, the way of measuring the quality of the generated sampels should be given by a classifier which is trained\n",
    "to classify between fake `class=0` (generated by our generator network) and real images `class=1` (from our bunch of images).\n",
    "\n",
    "The clue is now, that the generator should try to fool the discriminator.\n",
    "So, by adapting the generator weights the discriminator should fail to identify the fake images, and should output `class=1` (real images)\n",
    "when generated images are input. The crucial thing is, that we can directly get this feedback when stacking the generator on top\n",
    "of the discriminator to build our GAN framework. Because both are neural networks, we just can propagate the gradient \n",
    "through the discriminator to the generator, which can then adapts it weights to generate samples of better quality.\n",
    "In simple words, the generator should change the weights in a way to generate images which hold features the discriminator identifies\n",
    "as features from real images.\n",
    "When iteratively adapting the weights of the discriminator and generator, the performance of generated images should increase stepwise.\n",
    "This is the fascinating idea of _adversarial training_.\n",
    "\n",
    "\n",
    "<img src=\"images/adversarial_training_sketch.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "In a very figurative sense, the discriminator could be seen as painter which is able to classify between\n",
    "real images and fake images, because he knows a little bit about colors and art. We now would like to build a generator machine\n",
    "which produce nice photographs.\n",
    "The idea is, to fool the painter (discriminator) by changing the parameters of our generator machine.\n",
    "Because the painter has knowledge how \"real images\" look like, the feedback of him helps to let our generator machine generate\n",
    "images of better quality.\n",
    "\n",
    "<a name=\"gan_theory\"></a>\n",
    "#### Adversarial training\n",
    "After introducing the basic idea of adversarial training, let us now understand the math and focus on the algorithm itself.\n",
    " \n",
    "Our adversarial framework consists out of 2 networks:\n",
    "- the generator network $G$ (learn the mapping from noise $z$ to images $\\tilde{x}$)\n",
    "- the discriminator $D$ network (measures the image quality, by discriminating if the images are true `class=1` or fake `class=0`)\n",
    "\n",
    "The iterative update procedure of the framework is as follows:\n",
    "    1. Discriminator update: Train the discriminator to classify between fake and real images\n",
    "    2. Generator update: Train the generator to fool the generator\n",
    "    -  Repeat from beginning\n",
    "\n",
    "\n",
    "##### Discriminator update\n",
    "Sample noise vector from the latent space $z \\sim p(z)$.\n",
    "Generate new fake samples by feeding the sampled vector $z$ in to the generator $G(z)$ to obtain the new samples $\\tilde{x} \\sim G(z)$.\n",
    "Subsequently, we sample from the real distribution and obtain a bunch of samples $ x \\sim P_{r}$.\n",
    "We now train the discriminator using the binary cross entropy by changing the weights $w$ of the discriminator:\n",
    "\n",
    "$ \\mathcal{L}_{Dis} = \\min{ -\\mathbb{E}_{\\mathbf{x} \\sim p_{data}(\\mathbf{x})} [log(D_w(\\mathbf{x}))] - \\mathbb{E}_{\\mathbf{z} \\sim p_z(\\mathbf{z})} [log(1-D_w(G_{\\theta}(\\mathbf{z})))]}$\n",
    "\n",
    "This is just the typical supervised training of a classifier.\n",
    "\n",
    "\n",
    "##### Generator update\n",
    "Sample noise from the latent space $z \\sim p(z)$\n",
    "Generate new fake samples by feeding the noise into the generator $G(z)$ and obtain a bunch of generated samples $\\tilde{x} \\sim G(z)$\n",
    "Now we freeze the weights $w$ of the discriminator.\n",
    "Finally, we train the generator to fool the discriminator, by adapting the weights $\\theta$ of our generator network:\n",
    "\n",
    "$ \\mathcal{L}_{Gen} = \\max{ -\\mathbb{E}_{\\mathbf{z} \\sim p_z(\\mathbf{z})} [log(1-D_w(G_{\\theta}(\\mathbf{z})))]}$\n",
    "\n",
    "By iteratively passing these steps of discriminator and generator updates, we train our framework.\n",
    "\n",
    "### Architectures\n",
    "Building a powerful architecture of the discriminator and generator is rucial for successful GAN training.\n",
    "Remember, that the generator maps from the latent space into the data space.\n",
    "Hence, the input should be a 1D-vector of noise variables and the output should have image dimensions.\n",
    "In this case the output will have the dimension `(32, 32, 3)`. (3 color channels: RGB)\n",
    "\n",
    "[Radford, Metz, and Chintala](https://arxiv.org/abs/1511.06434) proposed stable architectures for generator and discriminator networks.\n",
    "These DCGAN \"guidelines\" can be summarized as follows:\n",
    "- Replace fully connected layers with convolutional layers\n",
    "- Do not use pooling layers, use striding instead\n",
    "- Make use of batch normalization in generator and discriminator to stabilize training<sup>[2](#myfootnote2)</sup>\n",
    "- Use [LeakyReLU](https://arxiv.org/pdf/1505.00853.pdf) activation in discriminator for better feedback<sup>[3](#myfootnote3)</sup>\n",
    "- Use a pyramidal topology in the generator by using transposed convolutions, to support a simple and strucutred latent space\n",
    "\n",
    "<img src=\"images/DCGAN_generator.png\" alt=\"drawing\" width=\"800\"/>\n",
    "<div style=\"text-align: right\"> image credit: Radford, Metz, Chintala </div>\n",
    "\n",
    "\n",
    "--- Footnotes\n",
    "\n",
    "<a name=\"myfootnote1\">1</a>: In contrast to e.g. _Variational Autoencoders_ the idea is not to \"fit the distribution in a space of compressed representation\"\n",
    "but to train a generator which approximates the real distribution directly.\n",
    "Remember that in VAEs we learn a mapping in to the latent space where we can \"fit\" a gaussian. Therefore, after the training we can just\n",
    "generate new samples by sampling from the latent space using the Gaussian prior.\n",
    "Because most problems are to complex, the Gaussian is not able to capture all modes, this leads to blurry images which is\n",
    "a well known problem for VAE generated samples. Furthermore, VAEs minimize the Kullback-Leibler divergence, which is not a well suitable distance measure.\n",
    "\n",
    "<a name=\"myfootnote2\">2</a>: Batch normalization is very important here. Due to the normalization of the gradients, it stabilizes the training.\n",
    "As we will see [later](#sngan_normalization) normalizing the gradients delivered by the discriminator, is crucial.\n",
    "\n",
    "<a name=\"myfootnote3\">3</a>: Using ReLU in the discriminator would lead to sparse gradient (no negative gradient could propagate back).\n",
    "Using LeakyReLU provides better feedback. Also pooling would provide sparse gradients.\n",
    "\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<a name=\"gan_code\"></a>\n",
    "## Implementation Vanilla GAN\n",
    "Let us start to implement our first GAN in Keras, to gain more insights of the training procedure.\n",
    "So let us first import the libaries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eos access: âœ—\n",
      "Python version 3.6.7\n",
      "\n",
      "TensorFlow version 1.13.1\n",
      "Keras version 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from platform import python_version\n",
    "import tutorial as tut\n",
    "\n",
    "print(\"Python version\", python_version())\n",
    "print(\"\\nTensorFlow version\", tf.__version__)\n",
    "print(\"Keras version\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "First of all we have to load our training data.\n",
    "Furthermore, we can have a look on the first 16 images of the CIFAR10 dataset.\n",
    "For the later training of networks it is from big advantage to preprocess our data, because neural networks prfoit from \n",
    "normalize data we rescale the images to [-1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from plotting import plot_images\n",
    "\n",
    "(images, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "plot_images(images[:16])\n",
    "x_train = 2 * (images / 255. - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Now we can design our generator and discriminator network.\n",
    "Let us begin with a straight forward implementation of the generator network, following the DCGAN guidelines.\n",
    "As noise input we sample from a `latent_dim = 64` dimensional latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              133120    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 4, 4, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 256)         3277056   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 16, 16, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 32, 32, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 32, 32, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 3)         1731      \n",
      "=================================================================\n",
      "Total params: 11,096,771\n",
      "Trainable params: 11,094,723\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "layers = keras.layers\n",
    "\n",
    "print('Generator')\n",
    "latent_dim = 64\n",
    "generator_input = layers.Input(shape=[latent_dim])\n",
    "x = layers.Dense(2 * 2 * 512, activation='relu')(generator_input)\n",
    "x = layers.Reshape([2, 2, 512])(x)\n",
    "x = layers.Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2DTranspose(64, (5, 5), padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(3, (3, 3), padding='same', activation='tanh')(x)\n",
    "generator = keras.models.Model(inputs=generator_input, outputs=x)\n",
    "print(generator.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we can see, we build a generator with ~ 10 M parameters, which maps from the latent space `(64,)` to the data space `(32,32,3)`.\n",
    "Notice, that using `tanh` as last activation is important, because we scaled the images to [-1,1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 512)         2097664   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 2,759,298\n",
      "Trainable params: 2,759,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Discriminator')\n",
    "discriminator_input = layers.Input(shape=[32, 32, 3])\n",
    "x = layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same')(discriminator_input)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2D(128, (4, 4), padding='same', strides=(2, 2))(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2D(256, (4, 4), padding='same', strides=(2, 2))(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2D(512, (4, 4), padding='same', strides=(2, 2))(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Dense(2, activation='softmax', kernel_regularizer=keras.regularizers.l1_l2(0.0004))(x)\n",
    "discriminator = keras.models.Model(inputs=discriminator_input, outputs=x)\n",
    "print(discriminator.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Furthermore, we created our discriminator which classifies the input images of shape `(32,32,3)` into `(2,)` classes (fake, real)\n",
    "holding ~2.5 M parameters.\n",
    "\n",
    "Now, we can compile our model by choosing an optimizer and setting the objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d_opt = keras.optimizers.Adam(lr=2e-4, beta_1=0.5, decay=0.0005)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=d_opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "After creating our discriminator model, we have to build and compile the GAN framework by stacking the discriminator on \n",
    "top of the generator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generative Adversarial Network\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 32, 32, 3)         11096771  \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 2)                 2759298   \n",
      "=================================================================\n",
      "Total params: 13,856,069\n",
      "Trainable params: 13,854,021\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('\\nGenerative Adversarial Network')\n",
    "gan_input = layers.Input(shape=[latent_dim])\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "GAN = keras.models.Model(gan_input, gan_output)\n",
    "print(GAN.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "After building the framework, we have to compile it.\n",
    "But before, we have to **freeze the weights of the discriminator**. (Remember that for training the generator we have to \n",
    "fix the discriminator weigths, because we want to fool the discriminator by drawing nice images, not by making our discriminator \n",
    "a bad classifier).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_trainable(model, trainable):\n",
    "    \"\"\" Function to freeze / unfreeze a model \"\"\"\n",
    "    model.trainable = trainable\n",
    "    for l in model.layers:\n",
    "        l.trainable = trainable\n",
    "\n",
    "g_opt = keras.optimizers.Adam(lr=2e-4, beta_1=0.5, decay=0.0005)\n",
    "make_trainable(discriminator, False)  # freezes the discriminator when training the GAN\n",
    "GAN.compile(loss='binary_crossentropy', optimizer=g_opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that after we compiled a model, calling `make_trainable` will have no effect untill compiling the model again.\n",
    "\n",
    "We now can design the training loop of our framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_gan(epochs=0, batch_size=64):\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        # Plot some fake images\n",
    "        noise = np.random.randn(batch_size, latent_dim)\n",
    "        generated_images = 255. * (generator.predict(noise) / 2. + 0.5)\n",
    "        plot_images(generated_images[:16])  # plot image\n",
    "    \n",
    "        perm = np.random.choice(50000, size=50000, replace='False')\n",
    "    \n",
    "        for i in range(50000//batch_size):\n",
    "    \n",
    "            # Create a mini-batch of data (X: real images + fake images, y: corresponding class vectors)\n",
    "            image_batch = x_train[perm[i*batch_size:(i+1)*batch_size], :, :, :]    # real images\n",
    "            noise_gen = np.random.randn(batch_size, latent_dim)\n",
    "            generated_images = generator.predict(noise_gen)                        # generated images\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = np.zeros([2*batch_size, 2])   # class vector\n",
    "            y[0:batch_size, 1] = 1\n",
    "            y[batch_size:, 0] = 1\n",
    "    \n",
    "            # Train the discriminator on the mini-batch\n",
    "            d_loss, d_acc = discriminator.train_on_batch(X, y)\n",
    "            losses[\"d\"].append(d_loss)\n",
    "            discriminator_acc.append(d_acc)\n",
    "    \n",
    "            # Create a mini-batch of data (X: noise, y: class vectors pretending that these produce real images)\n",
    "            noise_tr = np.random.randn(batch_size, latent_dim)\n",
    "            y2 = np.zeros([batch_size, 2])\n",
    "            y2[:, 1] = 1  # Fooling: We need to take the label 1, (real) because Keras will minimize the cross entropy in our model,\n",
    "                          # Switching the label to real here, will let us maximize as required . \n",
    "\n",
    "            # Train the generator on the mini-batch\n",
    "            g_loss = GAN.train_on_batch(noise_tr, y2)\n",
    "            losses[\"g\"].append(g_loss)\n",
    "            print(discriminator_acc[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now just could train our network by calling `train_gan(epochs=100)`.\n",
    "\n",
    "###### WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
    "-> This warning is harmless and just occurs, because we compiled the discriminator and later froze its weights for the generator training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gan_dir = tut.get_file(\"gan/models/vanilla_GAN/generator.h5\")\n",
    "pretrained_generator = keras.models.load_model(gan_dir)\n",
    "noise = np.random.randn(16, 64)\n",
    "generated_images = 255. * (pretrained_generator.predict(noise) / 2. + 0.5)\n",
    "plot_images(generated_images)  # plot images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Results\n",
    "\n",
    "As we can see the results are very noisy and the generator seems to output really similar image samples of relatively bad quality.\n",
    "In order not to judge too quickly, you should remember that generating images is a quiet complicated task. 32x32x3 = 3072 dimensional!\n",
    "The dataset holds 10 classes, with complicated structures. [MNIST](http://yann.lecun.com/exdb/mnist/) is comparatively much much easier.\n",
    "By randomly sampling from noise, you will never be able to generate a sample looking like any of the images, it will just be noise!\n",
    "\n",
    "Still, we can see that our model is only able to produce rough details and local regions of smooth colors, capturing only a single mode.\n",
    "\n",
    "\n",
    "Samples during training            |  Loss\n",
    ":-------------------------:|:-------------------------:\n",
    "<img src=\"https://cernbox.cern.ch/index.php/s/xDYiSmbleT3rip4/download?path=%2Fgan%2Fmodels%2Fvanilla_GAN&files=cifar10_vanilla.gif\" width=\"400\"/>  |  <img src=\"https://cernbox.cern.ch/index.php/s/xDYiSmbleT3rip4/download?path=%2Fgan%2Fmodels%2Fvanilla_GAN&files=loss.png\" width=\"400\"/>\n",
    "\n",
    "\n",
    "When we have a look on the loss we have no visible of convergence or anything which could tell us about successful training.\n",
    "We can just see that discriminator an generator ware on a same scale.\n",
    "\n",
    "\n",
    "For increasing the generation performance we need to understand what's wrong with the vanilla GAN training.\n",
    "\n",
    "### Problems training GANs\n",
    "\n",
    "<details><summary> <button type=\"button\">Display detailed text</button> </summary>\n",
    "<p>\n",
    "\n",
    "\n",
    "In general, training GANs is a very challenging task and needs a lot of fine tuning compared to supervised training of deep networks.\n",
    "The reason for this is, that we do not have a stationary minimization problem anymore, but two networks playing a _minmax game_.\n",
    "The updates of the the generator will highly affect the next step of the discriminator update and the other way round.\n",
    "Beside this:\n",
    "- Non-stationary minimization problem. Do not use optimizers with high momentum rates\n",
    "- Mode collapsing\n",
    "- Vanishing gradients\n",
    "- Meaningless loss metric\n",
    "\n",
    "are further issues of our vanilla GAN.\n",
    "\n",
    "##### Mode collapsing - \"Helvetica Scenario\"\n",
    "After the training, the generator outputs samples from a restricted phase space only.\n",
    "This is heavily connected to the control of the discriminator gradients. When the discriminator covers only a part of the modes in data,\n",
    "the feedback will only be informative for this modes. This heavily drives the generator to collapse towards this mode,\n",
    "which forces the discriminator to focus even more on this specific mode.\n",
    "\n",
    "<img src=\"https://cernbox.cern.ch/index.php/s/xDYiSmbleT3rip4/download?path=%2Fgan%2Fimages&files=mnist_mode_collapse.png\" alt=\"drawing\" width=\"487\"/>\n",
    "\n",
    "To solve this one can try to use:\n",
    "- Batch history (add in the present batch of generated samples, samples generated by the model in earlier iterations)\n",
    "- Add noise into the framework\n",
    "- Label smoothing or switching (see [non saturating GAN](#ns_gan))\n",
    "- Conditioning of GANs - change to semi supervised training by adding label information to generator and/or discriminator\n",
    "    - C-GAN : condition the generator to produce specific samples, [Mirza, Osindero](https://arxiv.org/abs/1411.1784)\n",
    "    - AC-GAN: let the discriminator learn a conditional probability over the classes, [Odena, Olah, Shlens](https://arxiv.org/abs/1610.09585)\n",
    "    \n",
    "\n",
    "##### Vanishing gradients\n",
    "For training a reasonable generator, the feedback of the discriminator is crucial.\n",
    "Therefore, one could think that training the discriminator more often than the generator could improve the training,\n",
    "because the feedback would be much more precise.\n",
    "The problem is, that for this scenario the feedback of the discriminator is almost zero.\n",
    "![vanishing gradients](https://cernbox.cern.ch/index.php/s/xDYiSmbleT3rip4/download?path=%2Fgan%2Fimages&files=vanishing_gradients.gif)\n",
    "<div style=\"text-align: right\"> image credit: Emanuele Sansone </div>\n",
    "When calculating the gradient for the generator update provided by a converged discriminator, one obtains vanishing feedback:\n",
    " \n",
    "$\\lim_{D \\rightarrow 0} \\frac{\\partial{}}{\\partial{\\theta}} \\log(1-D(G_{\\theta}(z))) = \\lim_{f \\rightarrow -\\infty} \\frac{\\partial{}}{\\partial{\\theta}}\\log\\left( 1- \\frac{1}{1+e^{-f_{\\theta}}} \\right) \\approx 0$\n",
    "\n",
    "Hence, having a strong discriminator will hinder the training, this is very bad!\n",
    "In order to prevent that, we used regularization (dropout + l1 + l2)  in the discriminator.\n",
    "\n",
    "#### Meaningless Loss\n",
    "By inspecting the loss of the discriminator and generator, we can see that they do not correlate with the image quality.\n",
    "(the discriminator is not trained to convergence). Hence, it is quiet hard to say if our framework reached a stable equilibrium.\n",
    "This is really bad for monitoring the training.\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<a name=\"wgan\"></a>\n",
    "## Wasserstein GANs\n",
    "\n",
    "<details><summary> <button type=\"button\">Display detailed text</button> </summary>\n",
    "<p>\n",
    "\n",
    "To overcome the issue of the meaningless metric and vanishing gradients.\n",
    "[Arjovsky, Chintala and Bottou](https://arxiv.org/abs/1701.07875) proposed to used the Wasserstein-1 as metric in the discriminator.\n",
    "Using the Wasserstein distance as metric has several advantages in comparison to the old minmax loss.\n",
    "The crucial feature of the Wasserstein distance is the meaningful distance measure even when distributions are disjunct.\n",
    "But before coming to the crucial difference, let us try to understand the Wasserstein distance.\n",
    "\n",
    "### Wasserstein or Earth Mover's distance\n",
    "Wasserstein-1 or _earth mover's distance_ describes the **minimal cost** to transform a distribution $P_{\\theta}$ into another disitribution $P_{r}$ and vice versa.\n",
    "The mathematical defintion is as follows:\n",
    "\n",
    "$\\mathcal{D}_W(P_r|| P_\\theta)= \\inf_{\\gamma \\in \\Pi(P_r, P_\\theta)} \\mathbb{E}_{(x,y) \\sim \\gamma}[||x-y||]$\n",
    "\n",
    "The Wasserstein distance can be understood using a very figurative example.\n",
    "Let us assume, we have two heaps of earth in the garden $P_{r}, P_{\\theta}$ and would like to know, what is the minimum ${\\inf}$ *work* we need to transform one heap of earth into the other one.\n",
    "In other words, how many shovels of earth $\\mathbb{E}_{(x,y)}$ we have to transport which distance $||x-y||$. (Work: mass * distance)\n",
    "The optimal transport plan $\\inf_{\\gamma \\in \\Pi(P_r, P_\\theta)}$ for this transformation, is given by the Wasserstein distance. \n",
    "\n",
    "<img src=\"https://cernbox.cern.ch/index.php/s/xDYiSmbleT3rip4/download?path=%2Fgan%2Fimages&files=earth_movers_distance.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "<a name=\"wgan_theory\"></a>\n",
    "### Improved training of GANs\n",
    "When interpreting the training of GANs as divergence minimization, the training of vanilla GANs is similar (assuming an optimal discriminator) to minimize the *Jensen-Shannon divergence* (JS divergence).\n",
    "The JS divergence do not provided a meaningful measure for disjoint distributions (no overlap).\n",
    "In contrast, the Wasserstein distance does (in the figurative example both heaps of earth are disjoint).\n",
    "Especially in the beginning of the GAN training, both distributions are disjoint. Because the discriminator can very easily discriminate perfectly between real and fake images.\n",
    "Furthermore, because of the easy formulation of the distance measure (mass * distance) we can expect smooth gradients. \n",
    "\n",
    "### Approximation of the Wasserstein distance using the discriminator (critic)\n",
    "Using the Kantorovich-Rubinstein duality we are able to construct the Wasserstein distance ourselves and the loss becomes:\n",
    "\n",
    "$\\mathcal{L}_{WGAN} = \\min_{ D_w \\in Lip_1} \\mathbb{E}_{x \\sim P_r}[D_w(x)] - \\mathbb{E}_{\\tilde{x} \\sim P_\\theta}{[D_w(\\tilde{x})]}$ ,\n",
    "\n",
    "where $D_w(x)$ is the discriminator network (in the WGAN setup called *critic* because the network is not trained to discriminate anymore).\n",
    "Basically the distance/loss $\\mathcal{L}_{WGAN}$ is formed, by subtracting the output of the critic applied on the fake samples from the critic applied on the real samples. \n",
    "It is important, that  $D \\in Lip_1$ denotes, that the function the critic network should approximate is a 1-Lipschitz function.\n",
    "(A 1-Lipschitz function is a function, which has a slope $m \\leq 1$ everywhere.)\n",
    "Therefore, the critic network we used for approximation has to carry this Lipschitz constrain<sup>[4](#myfootnote4)</sup> also.\n",
    "For implementing Wasserstein GANs, the are 2 possible methods to enforce the Lipschitz constrain:\n",
    "- Use weight clipping, which is less preferred<sup>[5](#myfootnote4)\n",
    "- Use the Gradient penalty\n",
    "\n",
    "[Gulrajani et. al.](https://arxiv.org/abs/1704.00028) proposed the **Gradient penalty** to construct the Lipschitz constrain by extending the loss $\\mathcal{L}_{WGAN}$ with:\n",
    "\n",
    "$\\mathcal{L}_{GP} = \\lambda\\; \\mathbb{E}_{\\hat{u} \\sim P_{\\hat{u}}}[(||\\nabla_{\\hat{u}}D_w(\\hat{u})||_2-1)^2]$\n",
    "\n",
    "where $\\lambda$ is a hyperparameter to scale the loss and $\\hat{u}=\\epsilon x + (1-\\epsilon)\\tilde{x}\\;,0 \\leq \\epsilon \\leq 1$\n",
    "is randomly sampled along straight lines between pairs of data and fake samples.\n",
    "In simple words, the gradient in the discriminator is forced to have norm $1$<sup>[6](#myfootnote6)</sup> everywhere between the distribution of real and fake samples.\n",
    "Implementing this \"objective\" makes explicitly clear, that the WGAN will not suffer from vanishing gradients.\n",
    "\n",
    "This are great news, now we can and **should train the critic network to convergence**, which will give us **non vanishing \n",
    "and precise** feedback.\n",
    "\n",
    "--- Footnotes\n",
    "\n",
    "<a name=\"myfootnote4\">4</a>: Easy interpretation: We need a constraint to train the discriminator to convergence, otherwise\n",
    " the discriminator could focus on one feature which differs between real and fake samples and won't converge\n",
    "\n",
    "<a name=\"myfootnote5\">5</a>: Weight clamping will heavily reduce the capacity of the discriminator which is unfavourable.\n",
    "\n",
    "<a name=\"myfootnote6\">6</a>: One could complain that by constraining the critic network to provide gradients with exactly norm $1$\n",
    "is not exactly the same as required by the Lipschitz constraint, which is right sided only $m \\leq 1$. It turns out that\n",
    "the both sided penalty, performs slightly better than the right sided gradient penalty. To understand this issue, one have to understand\n",
    "GAN training more in a way of gradient [control/normalization](#sngan_normalization).\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<a name=\"wgan_code\"></a>\n",
    "### Implementation of improved Wasserstein GANs - WGAN-GP (conditioned)\n",
    "After the short introduction into WGANs, let us try to implement our first own Wasserstein GAN using tf.contrib.GAN.\n",
    "This high-level library will make our life much easier.\n",
    "\n",
    "Furthermore, we try to condition our generator to produce samples from a specific class (eg. dog), following the [C-GAN approach](https://arxiv.org/abs/1411.1784)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from plotting import plot_images\n",
    "layers = tf.layers\n",
    "print(\"TensorFlow version\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let us begin to build our data pipeline, which will provide us with new data samples during the training.\n",
    "First we need to define our data generator.\n",
    "The data generator should output real samples (input for the discriminator) and noise (input for the generator)\n",
    "The variable LATENT_DIM defines the dimensionality of the latent space of the generator. (The noise distribution we sample from).\n",
    "\n",
    "Additionally, we will provide our generator and discriminator a label, to condition and stabilize our training process.\n",
    "These type of GANs are called [Conditional GANs](https://arxiv.org/abs/1610.09585) or supervised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_generator(LATENT_DIM):\n",
    "    while True:\n",
    "        (x_train, labels), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "        nsamples = x_train.shape[0]\n",
    "        images = 2 * (x_train / 255. - 0.5)\n",
    "        images = images.astype(np.float32)\n",
    "        noise = np.random.randn(nsamples, LATENT_DIM).reshape(nsamples, LATENT_DIM)\n",
    "        idx = np.random.permutation(nsamples)\n",
    "        noise = noise[idx]\n",
    "        images = images[idx]\n",
    "        labels = labels[idx]\n",
    "        for i in range(nsamples):\n",
    "            yield ((noise[i], labels[i]), (images[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Let us now check if our generator is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "generator_output = np.array(list(itertools.islice(data_generator(64), 16)))\n",
    "test_images = 255. * (generator_output[:,1] / 2. + 0.5)\n",
    "plot_images(test_images[:16])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "For training GANs we need to further define our generator and discriminator network.\n",
    "We start by defining our generator network, which should map from our noise + label space into the space of out images \n",
    "`(LATENT_DIM + LABEL --> IMAGE_DIM)`.\n",
    "Adding the label to the input of the gernator and discriminator, should enforce the generator to produce samples from the according class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LATENT_DIM = 64  # dimension of the latent space\n",
    "\n",
    "def generator_fn(inputs, latent_dim=LATENT_DIM):\n",
    "    x, labels = inputs\n",
    "    x = tf.concat([x, labels], axis=-1)\n",
    "    x = layers.Dense(4 * 4 * 256, activation='relu', input_shape=(latent_dim + 1,))(x)  #\n",
    "    x = tf.reshape(x, shape=[BATCH_SIZE, 4, 4, 256])\n",
    "    x = layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(3, (3, 3), padding='same', activation='tanh')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "After defining our generator network we need now to implement our discriminator.\n",
    "The task of the discriminator is to measure the similarity between the fake images (output of the generator) and the real images.\n",
    "So, the network maps from the image space into a 1D space where we can measure the 'distance' between the distributions \n",
    "of the real and generated images `(IMAGE_DIM + LABEL --> 1)`.\n",
    "Also here we add the class label to the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_fn(x, gen_in, drop_rate=0.25):\n",
    "    \"\"\" Discriminator network \"\"\"\n",
    "    noise, labels = gen_in\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3))(x)\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    labels = tf.tile(tf.reshape(labels, [BATCH_SIZE, 1, 1, 1]), [1, 32, 32, 1])\n",
    "    x = tf.concat([x, labels], axis=-1)\n",
    "    x = tf.contrib.layers.layer_norm(x)\n",
    "    x = layers.Conv2D(64, (4, 4), padding='same', strides=(2, 2))(x)\n",
    "    x = tf.contrib.layers.layer_norm(x)\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = tf.contrib.layers.layer_norm(x)\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = layers.Conv2D(128, (4, 4), padding='same', strides=(2, 2))(x)\n",
    "    x = tf.contrib.layers.layer_norm(x)\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = tf.contrib.layers.layer_norm(x)\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = layers.Conv2D(256, (4, 4), padding='same', strides=(2, 2))(x)\n",
    "    x = tf.contrib.layers.layer_norm(x)\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same')(x)\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Note that in WGANs we can not make use of batch normalization in the critic, because the gradient penalty is calculated between sample pairs.\n",
    "Therefore, [layer normalization](https://arxiv.org/abs/1607.06450) is a great alternative for normalization in the critic.\n",
    "\n",
    "So let us use the [Gradient Penalty](https://arxiv.org/abs/1704.00028):\n",
    "By penalizing the gradient to be 1, we enforce the lipschitz constraint needed to construct Wasserstein using the\n",
    "[Kantorovich-Rubinstein duality](https://cedricvillani.org/wp-content/uploads/2012/08/preprint-1.pdf)\n",
    "GP is the hyperparameter to weight the strength of the Lipschitz constrain. (higher GP --> stronger enforcing)\n",
    "We can make use of the preliminary implemented `wasserstein_loss` which evaluates $\\mathcal{L}_{WGAN}$, **without** enforcing a Lipschitz constrain.\n",
    "For this reason, we have to add the gradient penalty to the loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(model, add_summaries=True):\n",
    "\n",
    "    loss = tf.contrib.gan.losses.wasserstein_discriminator_loss(model, add_summaries=add_summaries)\n",
    "    gp_loss = GP * tf.contrib.gan.losses.wasserstein_gradient_penalty(model, epsilon=1e-10, one_sided=True, add_summaries=add_summaries)\n",
    "    loss += gp_loss\n",
    "\n",
    "    if add_summaries:\n",
    "        tf.summary.scalar('discriminator_loss', loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "After defining our objective, we can choose our training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32   # number of samples fed into the framework in each iteration\n",
    "GEN_LR = 0.0002   # learning rate of the generator\n",
    "DIS_LR = 0.0002   # learning rate of the discriminator\n",
    "GP = 10           # factor to scale the gradient penalty (higher means larger enforcing the Lipschitz constrain)\n",
    "N_CRIT = 5        # number of critic iterations per generator iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can very easily implement our framework as estimator using tf.gan, this will heavily simplify our training procedure.\n",
    "It is important to realize that we now train the critic `N_CRIT = 5` times, before updating the generator `1` time.\n",
    "This allows us to stabilize the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading gan/models/WGAN_GP from CERNBox\n"
     ]
    }
   ],
   "source": [
    "wgan_dir = tut.get_file(\"gan/models/WGAN_GP\")\n",
    "\n",
    "gan_estimator = tfgan.estimator.GANEstimator(\n",
    "    wgan_dir,\n",
    "    generator_fn=generator_fn,\n",
    "    discriminator_fn=discriminator_fn,\n",
    "    generator_loss_fn=tfgan.losses.wasserstein_generator_loss,\n",
    "    discriminator_loss_fn=discriminator_loss,\n",
    "    generator_optimizer=tf.train.AdamOptimizer(GEN_LR, 0.5),\n",
    "    discriminator_optimizer=tf.train.AdamOptimizer(DIS_LR, 0.5),\n",
    "    get_hooks_fn=tfgan.get_sequential_train_hooks(tfgan.GANTrainSteps(1, N_CRIT)),\n",
    "    config=tf.estimator.RunConfig(save_summary_steps=10, keep_checkpoint_max=1, save_checkpoints_steps=200),\n",
    "    use_loss_summaries=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "To train our estimator we can create a TensorflowDataset out of our data generator and design a function which outputs us\n",
    "batches of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def batched_dataset(BATCH_SIZE, LATENT_DIM, generator_fn):\n",
    "    Dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: generator_fn(LATENT_DIM), output_types=((tf.float32, tf.float32), (tf.float32)),\n",
    "        output_shapes=((tf.TensorShape((LATENT_DIM,)), tf.TensorShape((1,))), (tf.TensorShape((32, 32, 3)))))\n",
    "    return Dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Finally, let us train our framework using our gan_estimator and our data_pipeline.\n",
    "\n",
    "*We skip the training here and import a pretrained estimator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gan_estimator.train(lambda: batched_dataset(BATCH_SIZE, LATENT_DIM, generator), max_steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "To test the conditioning of the labels we can just build a sorted generator, and generate samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_cond_images\n",
    "\n",
    "def sorted_generator(LATENT_DIM):\n",
    "    while True:\n",
    "        nsamples = 50000\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "        labels = y_train\n",
    "        nsamples = x_train.shape[0]\n",
    "        images = 2 * (x_train / 255. - 0.5)\n",
    "        images = images.astype(np.float32)\n",
    "        noise = np.random.randn(nsamples, LATENT_DIM).reshape(nsamples, LATENT_DIM)\n",
    "        labels = np.expand_dims(np.tile(np.arange(10), 5000), axis=-1)\n",
    "        for i in range(nsamples):\n",
    "            yield ((noise[i], labels[i]), (images[i]))\n",
    "\n",
    "result = gan_estimator.predict(lambda: batched_dataset(BATCH_SIZE, LATENT_DIM, sorted_generator))\n",
    "images = []\n",
    "for i, image in zip(range(30), result):\n",
    "    images.append(255 * (image / 2. + 0.5))\n",
    "plot_cond_images(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name=\"wgan_results\"></a>\n",
    "\n",
    "### Results\n",
    "We now can have a look on the improvement of generated samples during the training and inspect the losses of the WGAN. The training took around 12h on a Nvidia 1080 GTX and was trained for 100k generator iterations.\n",
    "\n",
    "As we can see, the _gradient penalty_ is converging towards zero! This are great news, that means our critic is able to give a good estimate of the Wasserstein distance.\n",
    "\n",
    "##### Gradient Penalty Loss \n",
    "<img src=\"https://cernbox.cern.ch/index.php/s/xDYiSmbleT3rip4/download?path=%2Fgan%2Fmodels%2FWGAN_GP&files=GP_loss.svg\" alt=\"Gradient penalty * 10\" width=\"800\"/>\n",
    "\n",
    "If we look at the _critic loss_ we can see a convergence towards 0. (Note that due to our setup the critic gives a negative estimate of Wasserstein-1).\n",
    "These are really great news, because now we monitor the GAN training.\n",
    "Hence, we have an convergence of the Wasserstein metric we can expect good results.\n",
    "\n",
    "##### Critic Loss\n",
    "<img src=\"https://cernbox.cern.ch/index.php/s/xDYiSmbleT3rip4/download?path=%2Fgan%2Fmodels%2FWGAN_GP&files=critic_loss.svg\" alt=\"critic loss\" width=\"800\"/>\n",
    "\n",
    "So let's have a look on the final samples.\n",
    "\n",
    "\n",
    "![WGAN_GP samples](https://cernbox.cern.ch/index.php/s/xDYiSmbleT3rip4/download?path=%2Fgan%2Fmodels%2FWGAN_GP&files=cond_WGAN.gif)\n",
    "\n",
    "These samples look much better, than the ones obtained using the vanilla approach.\n",
    "Even for this relatively simple generator and discriminator model, we can clearly identify in the generated samples features belonging to the according class label.\n",
    "Congratulations we succesfully trained our first Wasserstein GAN!\n",
    "\n",
    "\n",
    "<a name=\"sngan\"></a>\n",
    "## Spectral Normalization for Generative Adversarial Networks - SN-GANs\n",
    "\n",
    "<details><summary> <button type=\"button\">Display detailed text</button> </summary>\n",
    "<p>\n",
    "\n",
    "<a name=\"sngan_normalization\"></a>\n",
    "### Gradient Penalty in terms of normalization \n",
    "To understand why SN-GANs are working, one have to interpret the gradient penalty in a little bit different way.\n",
    "The *gradient penalty* was introduced to estimate the Wasserstein distance between the distribution\n",
    "of real and fake samples using the _critic_ network. That was desirable when interpreting GAN training in terms of divergence minimization,\n",
    "because the Wasserstein distance is a much more suitable distance measure for disjoint distributions the the JS-divergence.\n",
    "Another way to review the gradient penalty is in a way somehow to normalization/ regularization.\n",
    "Remember, that for training vanilla GANs, using regularization and normalization (noise, regularizer, batch normalization) was crucial\n",
    "for obtaining reasonable results.\n",
    "\n",
    "<a name=\"ns_gan\"></a>\n",
    "To overcome the issue of *vanishing gradients* already in [Goodfellow et al.](https://arxiv.org/abs/1406.2661) an alternative\n",
    "loss was proposed, which is known as _label switching_ (because for implementation you just have to switch the labels of true and fakes).\n",
    "\n",
    "$ \\mathcal{L}_{NS, Gen} =  -\\mathbb{E}_{\\mathbf{z} \\sim p_z(\\mathbf{z})} [log(D(G_{\\theta}(\\mathbf{z})))]$\n",
    "\n",
    "The gradients of the discriminator do not vanish anymore, but can provide very instable updates. [Arjovsky and Bottou](https://arxiv.org/abs/1701.04862)\n",
    "showed, that the provided gradients for a noisy discriminator follows a cauchy distribution (infinite expectation and variance).\n",
    "In a more figurative sense, samples which lie outside of the support of the real and fake images will be very noisy and can blow\n",
    "up massively which disturbs the training.\n",
    "Therefore, penalizing large gradients in the discriminator is from major importance.\n",
    "These considerations explain the observation, that GANs using the \"non saturating loss\" and the gradient penalty instead of _Wasserstein_ + GP\n",
    "are an alternative and stable GAN setup.\n",
    "\n",
    "<a name=\"sngan_theory\"></a>\n",
    "### Spectral Normalization\n",
    "\n",
    "The observation that stabilizing the gradient is a suitable way to train NSGANs (non saturating GANs), leads\n",
    "to idea to implement the Lipschitz constrain in a much more direct way. (Remember, we have to update the critic several times\n",
    "to get good feedback for ther generator).\n",
    "[Miyato, Kataoka, Koyama, Yoshida](https://arxiv.org/abs/1802.05957) proposed to do this, by normalizing the discriminator \n",
    "weights using the spectral norm.\n",
    "This will have the big advantage that the discriminator do not need to be updated several times, which increase the speed \n",
    "of thw GAN training.\n",
    "\n",
    "#### Spectral norm\n",
    "\n",
    "\n",
    "Let us remember the definition of the spectral norm:\n",
    "\n",
    "$\\sigma(\\mathbf{W}) = ||\\mathbf{W}||_{2} = \\max_{x\\neq 0} \\frac{||\\mathbf{W}x||_2}{||x||_2} = \\max_{||x||_2=1} ||\\mathbf{W}x||_2$.\n",
    "\n",
    "Figuratively speaking, the spectral norm of $W$ is the maximum stretch factor of a unit vector $x$ after multiplication with matrix $W$.\n",
    "\n",
    "<img src=\"https://cernbox.cern.ch/index.php/s/xDYiSmbleT3rip4/download?path=%2Fgan%2Fimages&files=streched_vector.png\" alt=\"drawing by Quartl - wikipedia\" width=\"300\"/>\n",
    "<div style=\"text-align: right\"> image credit: Quartl, wikipedia </div>\n",
    "\n",
    "This allows us to draw a connection between the Lipschitz norm and spectral normalization.\n",
    "\n",
    "So we can express the Lipschitz norm using the spectral norm:\n",
    "\n",
    "$||D(x)||_{\\mathrm{Lip}} = \\sup_{x} \\sigma(\\nabla_x D(x))=  \\sup_{x} \\sigma(\\nabla_x Wx) = \\sigma(W)$\n",
    " \n",
    "We cann see directly, that for enforcing a similar Lipschitz constrain as used in WGAN-GP $||D(x)||_{\\mathrm{Lip}} \\leq 1$\n",
    "we can just normalize the weights $W$ using: \n",
    "\n",
    "$\\mathbf{W}_{SN}=\\frac{\\mathbf{W}}{\\sigma(\\mathbf{W})}$\n",
    "\n",
    "Because calculating the spectral norm can be quiet time consuming, the proposed approach is to use a fast approximation of the spectral norm\n",
    "using the _power iteration method_.\n",
    "\n",
    "Note that this type of normalization is different then typical regularization like L1 or L2, because using spectral\n",
    "normalization we are **not** adding an additional penalty term to the objective.\n",
    "\n",
    "In a figurative sense, just think of the normalization of the SN-GAN, as referee to control the gradient.\n",
    "Our discriminator now get as as input a vector $f$ of features. In the first layer the weight matrix $W$ is multiplied with this vector $f$.\n",
    "(normal transformation in fully connected layers). So the feature vector is rotated and stretched.\n",
    "Now, we constrain the weight matrix $W$ with the spectral norm. Hence, no transformations with a stretching factor larger than 1\n",
    "is allowed (just see the image of the spectral norm for an easy understanding). These normalization helps to prevent that\n",
    "the layer focus on a specific feature (direction) only which would induce large gradients.\n",
    "This helps to control the gradients of the discriminator outside the distribution of real and fake samples and prevents mode collapsing.\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<a name=\"sngan_code\"></a>\n",
    "## Spectral Normalization GANs for Cosmic Ray induced Air Showers\n",
    "\n",
    "After dealing with the CIFAR dataset let us now tackle our first **physics dataset** with GANs:\n",
    "a dataset of cosmic ray induced air showers.\n",
    "When ultra-high energy cosmic rays (UHECRs) penetrate the atmosphere of the earth, they interact with the air molecules and \n",
    "particle cascades are created. For air showers induced by UHECRs (energies > 10 EeV) the footprint on the Earth's surface\n",
    "is in the order of several 10 kmÂ².\n",
    "The dataset contains footprints of air showers measured by observatories like the [Pierre Auger Observatory](https://www.auger.org/)\n",
    "and induced by cosmic rays between 1 - 100 EeV and was used to train the first Wasserstein GAN on physics data [Comput Softw Big Sci (2018) 2: 4.](https://link.springer.com/article/10.1007%2Fs41781-018-0008-x).\n",
    "The dataset was generated using a parametrized simulation, and described in [Astropart. Phys. 97 (2017) 46](https://www.sciencedirect.com/science/article/pii/S0927650517302219?via%3Dihub),\n",
    "additionally [you can download the code](https://git.rwth-aachen.de/DavidWalz/airshower).\n",
    "\n",
    "Note that several things changed, after switching the dataset from photographs to physics:\n",
    "\n",
    "|Type| Signal Patterns (Calorimeter images)        |  Pictures           |\n",
    "| :------------- :| :------------- :|:-------------:|\n",
    "| Channels | many, up to tenth of layers   | 3 (RGB) |\n",
    "| Resolution | relatively low (20 x 20) | high resolution (higher than 1000 x 1000)    |\n",
    "| Pixel range | several magnitudes, **logarithmic**  | 0-255, **linear**|\n",
    "| Distribution pixels | sparse, high local correlations | coherent, high local and global correlations |\n",
    "\n",
    "Especially the logarithmic distribution of signals and the sparsity offer a new challenge.\n",
    "\n",
    "The SN-GAN is a nice alternative to the Wasserstein GAN, by \"encoding\" the Lipschitz constrain directly in the weights of\n",
    "the discriminator.\n",
    "For this reason, let us implement our first SN-GAN.\n",
    "\n",
    "## Implementation of SN-GAN\n",
    "\n",
    "No we are going to implement a Generative Adversarial Network using spectral normalization in the disciriminator.\n",
    "\n",
    "First of all we need the basic imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tutorial as tut\n",
    "\n",
    "layers = tf.layers\n",
    "tfgan = tf.contrib.gan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LATENT_DIM = 512\n",
    "path_cr = tut.get_file(\"gan/data/airshower_footprints.npz\")\n",
    "\n",
    "def cr_batched_dataset(BATCH_SIZE, LATENT_DIM, generator_fn):\n",
    "    Dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: generator_fn(LATENT_DIM), output_types=(tf.float32, tf.float32),\n",
    "        output_shapes=(tf.TensorShape((LATENT_DIM,)), tf.TensorShape((9, 9, 1))))\n",
    "    return Dataset.batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "def cr_data_generator(LATENT_DIM):\n",
    "    while True:\n",
    "        file = np.load(path_cr)\n",
    "        footprints = file['shower_maps']\n",
    "        nsamples = footprints.shape[0]\n",
    "        noise = np.random.randn(nsamples, LATENT_DIM).reshape(nsamples, LATENT_DIM)\n",
    "        idx = np.random.permutation(nsamples)\n",
    "        noise = noise[idx]\n",
    "        footprints = footprints[idx]\n",
    "        for i in range(nsamples):\n",
    "            yield (noise[i], footprints[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let us check the pipeline and plot a few air shower footprints from the \"real dataset\".\n",
    "The footprints were already preprocessed using $S' = log10(S+1)$ and by shifting the hottest station into the center of \n",
    "the footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_multiple_footprints\n",
    "import itertools\n",
    "\n",
    "test_footprints = np.array(list(itertools.islice(cr_data_generator(0), 16)))[:, 1]\n",
    "plot_multiple_footprints(test_footprints)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "To generate air shower footprints we now can start to implement our generator and discriminator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LATENT_DIM=80\n",
    "\n",
    "def generator_fn_cr(x, latent_dim=LATENT_DIM):\n",
    "    x = layers.Dense(1 * 1 * 256, activation='relu', input_shape=(latent_dim,))(x)  #\n",
    "    x = tf.reshape(x, shape=[BATCH_SIZE, 1, 1, 256])\n",
    "    x = layers.Conv2DTranspose(256, (3, 3), strides=(3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), strides=(3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(1, (3, 3), padding='same', kernel_initializer=tf.initializers.random_uniform(minval=0, maxval=2.), activation='relu')(x)\n",
    "    return x\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "This generator just follows the typical DCGAN structure using transposed convolutions and maps from `(laten_dim,)` to footprints\n",
    "with shape`(9,9,1)`.\n",
    "\n",
    "Note that in the last layer we need to have a 'ReLU' activation, as the footprints are very sparse.\n",
    "In the early stage of the training, this can lead to dying ReLUs and sparse gradients, hence we can initialize the\n",
    "bias vector to 0 (default) and the weights between [0, 2] to overcome this issue.\n",
    "\n",
    "Thereafter, we can build our discriminator. Here, we need to implement spectral normalization in our layers.\n",
    "\n",
    "### Implementation of the Spectral norm\n",
    "The implementation of the spectral norm is relatively straight forward, we just have to control the weights in the respective layer.\n",
    "Hence, we have to wrap the normalization around the normal layer.\n",
    "\n",
    "Let us try to build a fully connected layer using spectral normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ganlayers import spectral_norm  # function returns W / SN(W), normalized weight matrix using the power iteration method\n",
    "\n",
    "def dense_sn(inputs, units, name,\n",
    "             activation_fn=None,\n",
    "             use_bias=True,\n",
    "             kernel_initializer=tf.glorot_uniform_initializer(),\n",
    "             bias_initializer=tf.zeros_initializer(),\n",
    "             use_gamma=False,\n",
    "             factor=None):\n",
    "\n",
    "    input_shape = inputs.get_shape().as_list()\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "        kernel = tf.get_variable('kernel', shape=(input_shape[-1], units), initializer=kernel_initializer)  # create new weight matrix\n",
    "        outputs = tf.matmul(inputs, spectral_norm(kernel, use_gamma=use_gamma, factor=factor))  # apply linear transformation\n",
    "        if use_bias is True:\n",
    "            bias = tf.get_variable('bias', shape=(units,), initializer=bias_initializer)\n",
    "            outputs = tf.nn.bias_add(outputs, bias)  # add bias\n",
    "        if activation_fn is not None:\n",
    "            outputs = activation_fn(outputs)  # apply non-linear activation to the output \n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "We can now use the layer to build the discriminator. (The layer `conv2d_sn` is implemented in a similar way as `dense_sn`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ganlayers import conv2d_sn\n",
    "\n",
    "def discriminator_fn_cr(x):\n",
    "    x = conv2d_sn(x, 64, (3, 3), name='sn_conv00', padding='same')\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = conv2d_sn(x, 64, (4, 4), name='sn_conv01', padding='same', strides=(2, 2))\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = conv2d_sn(x, 128, (3, 3), name='sn_conv10', padding='same')\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = conv2d_sn(x, 128, (4, 4), name='sn_conv11', padding='same', strides=(2, 2))\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = conv2d_sn(x, 256, (3, 3), name='sn_conv20', padding='same')\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = dense_sn(x, 1, name='output')\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GEN_LR = 0.0001\n",
    "DIS_LR = 0.0001\n",
    "GP = 10\n",
    "N_CRIT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "After the last layer we do not need to apply an activation, hence this can be controlled using the loss provided by `tf.gan`.\n",
    "\n",
    "Subsequently, we can build our estimator.\n",
    "Remember that we need the **non saturating** loss `tfgan.losses.modified_generator_loss`, to prevent vanishing gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "sn_dir = tut.get_file(\"gan/models/SN_GAN\")\n",
    "\n",
    "gan_estimator = tfgan.estimator.GANEstimator(\n",
    "    sn_dir,\n",
    "    generator_fn=generator_fn_cr,\n",
    "    discriminator_fn=discriminator_fn_cr,\n",
    "    generator_loss_fn=tfgan.losses.modified_generator_loss,\n",
    "    discriminator_loss_fn=tfgan.losses.modified_discriminator_loss,\n",
    "    generator_optimizer=tf.train.AdamOptimizer(GEN_LR, 0.5),\n",
    "    discriminator_optimizer=tf.train.AdamOptimizer(DIS_LR, 0.5),\n",
    "    get_hooks_fn=tfgan.get_sequential_train_hooks(tfgan.GANTrainSteps(1, N_CRIT)),\n",
    "    config=tf.estimator.RunConfig(save_summary_steps=100, keep_checkpoint_max=3, save_checkpoints_steps=10000),\n",
    "    use_loss_summaries=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Afterwards, we could train our estimator.\n",
    "\n",
    "### Results\n",
    "But instead training, we load a pretrained model again which was trained around 5h on a Nvidia 1080 GTX and plot some \n",
    "air shower footprints generated by our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gan_estimator.train(lambda: cr_batched_dataset(BATCH_SIZE, LATENT_DIM, cr_data_generator), max_steps=1000)\n",
    "iter = gan_estimator.predict(lambda: cr_batched_dataset(BATCH_SIZE, LATENT_DIM, cr_data_generator))\n",
    "generated = []\n",
    "\n",
    "for i, gen_foot in zip(range(1000), iter):\n",
    "    generated.append(gen_foot)\n",
    "\n",
    "generated = np.array(generated)    \n",
    "plot_multiple_footprints(generated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see concentrated showers in the center of the array cutout, and a decrease of signals for stations with\n",
    "higher distances to the shower core. This exactly what we would expect from physics.\n",
    "\n",
    "Let us now do a more quantitative analysis of our generated showers and compare the distributions of total signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_total_signal\n",
    "import tutorial as tut\n",
    "\n",
    "path_cr = tut.get_file(\"gan/data/airshower_footprints.npz\")\n",
    "file = np.load(path_cr)\n",
    "data = file['shower_maps'][0:1000]\n",
    "\n",
    "plot_total_signal(fake=np.sum(generated, axis=(3, 2, 1)), data=np.sum(\n",
    "    data, axis=(3, 2, 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Furthermore, we can investigate the sparsity of the images and compare if the distributions of stations with measured signals \n",
    "is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_cell_number_histo\n",
    "\n",
    "plot_cell_number_histo(fake=np.sum(generated > 0, axis=(\n",
    "    3, 2, 1)), data=np.sum(data > 0, axis=(3, 2, 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "###### Discriminator Loss \n",
    "When studying the loss of the discriminator we can not see any kind of convergence.\n",
    "We have still the same issue of not estimating a distance in the discriminator but classifying only.\n",
    "<img src=\"https://cernbox.cern.ch/index.php/s/xDYiSmbleT3rip4/download?path=%2Fgan%2Fmodels%2FSN_GAN&files=loss.svg\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "###### Generated samples during training\n",
    "<img src=\"https://cernbox.cern.ch/index.php/s/xDYiSmbleT3rip4/download?path=%2Fgan%2Fmodels%2FSN_GAN&files=airshower_SN_GAN.gif\" width=\"600\"/>\n",
    "\n",
    "\n",
    "## Calorimeter images\n",
    "\n",
    "Let us now put all together and build a combination of spectral normalization and WGAN.\n",
    "Because the _gradient penalty_ put a similar constraint on the critic/discriminator but on a different way than using\n",
    "spectral normalization, as you can see in the following table.\n",
    "\n",
    "##### Differences between Spectral Normalization and Gradient Penalty\n",
    "| Wasserstein | Spectral Normalization |\n",
    "| :-------------: | :-------------: |\n",
    "| constrain gradient directly | uses weight normalization |\n",
    "| non stationary training routine \"local normalization\" | relatively stable training \"global normalization\" |\n",
    "| $\\checkmark$ nearly no constrain of feature learning | $\\times$ can reduce complexity of feature space |\n",
    "| $\\times$ Needs $\\geq 5$ discriminator iterations | $\\checkmark$ only $1$ discriminator iteration needed |\n",
    "| $\\times$ Needs tuning of learning rates an \"ncr\" iterations | $\\checkmark$ stable training for a wide range of parameters |\n",
    "| $\\checkmark$ provides meaningful metric | $\\times$ do not provides meaningful metric |\n",
    "\n",
    " So let us take the best of both worlds an combine both techniques. \n",
    "\n",
    "### Spectral Normalization in the generator\n",
    "\n",
    "Recently, it was found that the singular values of the generator are related to the GAN performance.\n",
    "[Odena et al.](https://arxiv.org/abs/1802.08768) proposed to use __Jacobian clamping__ to stabilize the training process.\n",
    "Since, spectral normalization is performing similar we will use spectral normalization instead.\n",
    "\n",
    "### Implementation\n",
    "Let us use for this last GAN implementation a much more complicated dataset as very similar used in [Erdmann, Glombitza, Quast](https://link.springer.com/article/10.1007%2Fs41781-018-0019-7).\n",
    "For simplicity reasons we are only using 3 layers and a single energy of 100 GeV electrons.\n",
    "Hence, using label conditioning is useless in this setup. \n",
    "\n",
    "So let us begin to implement the data pipeline and plot some calorimeter images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from plotting import plot_calo_images\n",
    "import tutorial as tut\n",
    "\n",
    "path_calo = tut.get_file(\"gan/data/3_layer_calorimeter_padded.npz\")\n",
    "\n",
    "def calo_batched_dataset(BATCH_SIZE, LATENT_DIM, generator_fn):\n",
    "    Dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: generator_fn(LATENT_DIM), output_types=(tf.float32, tf.float32),\n",
    "        output_shapes=(tf.TensorShape((LATENT_DIM,)), tf.TensorShape((15, 15, 3))))\n",
    "    return Dataset.batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "def calo_data_generator(LATENT_DIM):\n",
    "    while True:\n",
    "        calo_ims = np.load(path_calo)['data']\n",
    "        nsamples = calo_ims.shape[0]\n",
    "        calo_ims = np.log10(calo_ims+1)\n",
    "        calo_ims = calo_ims.astype(np.float32)\n",
    "        noise = np.random.randn(nsamples, LATENT_DIM).reshape(nsamples, LATENT_DIM)\n",
    "        idx = np.random.permutation(nsamples)\n",
    "        noise = noise[idx]\n",
    "        calo_ims = calo_ims[idx]\n",
    "        for i in range(nsamples):\n",
    "            yield (noise[i], calo_ims[i])\n",
    "\n",
    "\n",
    "import itertools\n",
    "images = np.array(list(itertools.islice(calo_data_generator(1), 3)))[:, 1]\n",
    "images = 10**images - 1\n",
    "plot_calo_images(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can observed sparse showers evolving in the electromagnetic sampling calorimeter.\n",
    "Furthermore, we can see that our calorimeter features a hexagonal grid. Therefore, we use offset coordinates as described\n",
    "in [Astropart. Phys. 97 (2017) 46](https://www.sciencedirect.com/science/article/pii/S0927650517302219)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "layers = tf.layers\n",
    "tfgan = tf.contrib.gan\n",
    "from ganlayers import conv2d_transpose_sn, conv2d_sn, dense_sn\n",
    "LATENT_DIM=64\n",
    "\n",
    "def generator_fn(x, latent_dim=LATENT_DIM):\n",
    "    x = layers.Dense(3 * 3 * 256, activation='relu')(x)  #\n",
    "    x = tf.reshape(x, shape=[BATCH_SIZE, 3, 3, 256])\n",
    "    x = conv2d_transpose_sn(x, 256, (4, 4), strides=(2, 2), padding='same', name='sn_conv_gen_transposed01', activation=tf.nn.relu)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = conv2d_transpose_sn(x, 128, (3, 3), strides=(2, 2), padding='valid', name='sn_conv_gen_transposed02', activation=tf.nn.relu)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = conv2d_transpose_sn(x, 64, (3, 3), padding='valid', name='sn_conv_gen_transposed03', activation=tf.nn.relu)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = conv2d_sn(x, 64, (3, 3), name=\"sn_gen_conv01\", padding='same', activation=tf.nn.relu)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = conv2d_sn(x, 3, (3, 3), name=\"sn_gen_conv02\", padding='same', kernel_initializer=tf.initializers.random_uniform(minval=0.1, maxval=100.), activation=tf.nn.relu)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the generator we make use of spectral normalization and batch normalization.\n",
    "Note, that we again uses the initialization trick in the last layer of the generator to overcome dying ReLUs and sparse gradients which can lead to a collapse of the training.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_fn(x, drop_rate=0.25):\n",
    "    \"\"\" Discriminator network \"\"\"\n",
    "    x = conv2d_sn(x, 64, (3, 3), name=\"sn_conv01\", padding='same')\n",
    "    x = tf.contrib.layers.layer_norm(x)\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = conv2d_sn(x, 64, (5, 5), name=\"sn_conv02\", padding='same', strides=(2, 2))\n",
    "    x = tf.contrib.layers.layer_norm(x)\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = conv2d_sn(x, 128, (3, 3), name=\"sn_conv03\", padding='same')\n",
    "    x = tf.contrib.layers.layer_norm(x)\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = conv2d_sn(x, 128, (4, 4), name=\"sn_conv04\", padding='same', strides=(2, 2))\n",
    "    x = tf.contrib.layers.layer_norm(x)\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = conv2d_sn(x, 256, (3, 3), name=\"sn_conv05\", padding='same')\n",
    "    x = tf.contrib.layers.layer_norm(x)\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = conv2d_sn(x, 512, (3, 3), name=\"sn_conv06\", padding='same')\n",
    "    x = tf.contrib.layers.layer_norm(x)\n",
    "    x = tf.nn.leaky_relu(x, 0.2)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = dense_sn(x, 1, name='sn_dense01')\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "After we successfully implemented our generator and critic network, we need to implement the Wasserstein loss with gradient penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(model, add_summaries=True):\n",
    "\n",
    "    loss = tf.contrib.gan.losses.wasserstein_discriminator_loss(model, add_summaries=add_summaries)\n",
    "    gp_loss = GP * tf.contrib.gan.losses.wasserstein_gradient_penalty(model, epsilon=1e-10, one_sided=True, add_summaries=add_summaries)\n",
    "    loss += gp_loss\n",
    "\n",
    "    if add_summaries:\n",
    "        tf.summary.scalar('discriminator_loss', loss)\n",
    "\n",
    "    return loss\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "To start generating calorimeter samples let us build our framework using the GANEstimator and set the training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "GEN_LR = 0.0001\n",
    "DIS_LR = 0.0001\n",
    "GP = 10\n",
    "N_CRIT = 5\n",
    "wgan_sn_dir = tut.get_file(\"gan/models/WGAN_SN\")\n",
    "\n",
    "\n",
    "gan_estimator = tfgan.estimator.GANEstimator(\n",
    "    wgan_sn_dir,\n",
    "    generator_fn=generator_fn,\n",
    "    discriminator_fn=discriminator_fn,\n",
    "    generator_loss_fn=tfgan.losses.wasserstein_generator_loss,\n",
    "    discriminator_loss_fn=discriminator_loss,\n",
    "    generator_optimizer=tf.train.AdamOptimizer(GEN_LR, 0.5, 0.9),\n",
    "    discriminator_optimizer=tf.train.AdamOptimizer(DIS_LR, 0.5, 0.9),\n",
    "    get_hooks_fn=tfgan.get_sequential_train_hooks(tfgan.GANTrainSteps(1, N_CRIT)),\n",
    "    config=tf.estimator.RunConfig(save_summary_steps=100, keep_checkpoint_max=3, save_checkpoints_steps=10000),\n",
    "    use_loss_summaries=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Again we load a pretrained model and inspect first samples generated by our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_average_image, plot_calo_images\n",
    "\n",
    "calo_iter = gan_estimator.predict(lambda: calo_batched_dataset(BATCH_SIZE, LATENT_DIM, calo_data_generator))\n",
    "generated_calo = []\n",
    "for i, image in zip(range(1000), calo_iter):\n",
    "    generated_calo.append(10**image - 1)\n",
    "    if i%100 == 0:\n",
    "        print(\"iteration\", i)\n",
    "generated_calo = np.array(generated_calo)\n",
    "plot_calo_images(generated_calo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "We can further investigate the correlations between the layer.\n",
    "It is from major importance that our generative model is able to capture this correlations!\n",
    "\n",
    "Note that genrating new samples using jupyter notebooks on a CPU can be quiet time consuming.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import plot_layer_correlations\n",
    "\n",
    "path_calo = tut.get_file(\"gan/data/3_layer_calorimeter_padded.npz\")\n",
    "calo_ims = np.load(path_calo)['data'][:1000]\n",
    "plot_layer_correlations(np.sum(calo_ims, axis=(1, 2)), datatype='data')\n",
    "plot_layer_correlations(np.sum(generated_calo, axis=(1, 2)), datatype='generated')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "Finally, we will have a look on the occupancy of the generated and real samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plotting import plot_cell_number_histo\n",
    "plot_cell_number_histo(fake=np.sum(generated_calo > 0, axis=(1, 2, 3)), data=np.sum(calo_ims > 0, axis=(1, 2, 3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "It is a well known in the HEP community (see [here](https://link.springer.com/article/10.1007%2Fs41781-018-0019-7) or [here](https://journals.aps.org/prd/abstract/10.1103/PhysRevD.97.014021)),\n",
    "that the sparsity in calorimeters is a big challenge and needs further investigations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
